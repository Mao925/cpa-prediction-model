# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import lightgbm as lgb
import matplotlib.pyplot as plt
import matplotlib.font_manager
import warnings
import io

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
# Streamlit Cloudç’°å¢ƒãªã©ã€ãƒ•ã‚©ãƒ³ãƒˆãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å ´åˆã‚’è€ƒæ…®
try:
    font_path = matplotlib.font_manager.findfont(matplotlib.font_manager.FontProperties(family='IPAexGothic'))
    if font_path:
        plt.rcParams['font.family'] = 'IPAexGothic'
except:
    # ãƒ•ã‚©ãƒ³ãƒˆãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯è­¦å‘Šã‚’å‡ºã™ï¼ˆã‚¨ãƒ©ãƒ¼ã«ã¯ã—ãªã„ï¼‰
    st.warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆIPAexGothicï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚°ãƒ©ãƒ•ã®æ—¥æœ¬èªãŒæ–‡å­—åŒ–ã‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")


# è­¦å‘Šã‚’éè¡¨ç¤ºã«ã™ã‚‹
warnings.filterwarnings('ignore')

# Matplotlibã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®š
plt.style.use('seaborn-v0_8-whitegrid')

# ============== Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIè¨­å®š ==============
st.set_page_config(
    page_title="CPAäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« v2.1",
    page_icon="ğŸ› ï¸",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ã‚«ã‚¹ã‚¿ãƒ CSSã§è¦‹ãŸç›®ã‚’èª¿æ•´ ---
st.markdown("""
<style>
    .stMetric {
        border-radius: 10px;
        padding: 15px;
        background-color: #f0f2f6;
    }
    .st-emotion-cache-1r4qj8v {
        border-radius: 10px;
    }
</style>
""", unsafe_allow_html=True)


# ============== é–¢æ•°ã®å®šç¾© ==============

@st.cache_data
def load_and_preprocess_data(file_all, file_30d):
    """
    2ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã‚’è¡Œã†é–¢æ•°ã€‚
    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã®è‡ªå‹•åˆ¤åˆ¥
    - ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã¸ã®é‡ã¿ä»˜ã‘
    - ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ï¼ˆä¸è¦æ–‡å­—å‰Šé™¤ã€å‹å¤‰æ›ï¼‰
    - å¤–ã‚Œå€¤é™¤å»ï¼ˆIQRæ³•ï¼‰
    """
    if file_all is None or file_30d is None:
        return None, None, "ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰2ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
    
    log_messages = []

    def read_csv_robust(file):
        # BOMä»˜ãUTF-8ã€Shift_JISã€é€šå¸¸ã®UTF-8ãªã©è¤‡æ•°ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã‚’è©¦ã™
        encodings = ['utf-8-sig', 'shift_jis', 'cp932', 'utf-8']
        file.seek(0)
        for encoding in encodings:
            try:
                return pd.read_csv(file, encoding=encoding)
            except UnicodeDecodeError:
                file.seek(0)
                continue
        raise UnicodeDecodeError(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.name}' ã‚’ã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚‚èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")

    try:
        df_all = read_csv_robust(file_all)
        df_30d = read_csv_robust(file_30d)
        log_messages.append("âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
    except Exception as e:
        return None, None, f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"

    # ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã«é‡ã¿ã‚’ä»˜ã‘ã¦ã€ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’é‡è¦–ã•ã›ã‚‹
    df_all['weight'] = 1.0
    df_30d['weight'] = 2.0
    log_messages.append(f"âœ… ãƒ¢ãƒ‡ãƒ«ãŒç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿({file_30d.name})ã‚’é‡è¦–ã™ã‚‹ã‚ˆã†ã«ã€é‡ã¿ã‚’2.0ã«èª¿æ•´ã—ã¾ã—ãŸã€‚")
    
    df = pd.concat([df_all, df_30d], ignore_index=True)
    
    # ã‚«ãƒ©ãƒ åã®ç©ºç™½ã‚’é™¤å»
    df.columns = df.columns.str.replace(' ', '').str.replace('ã€€', '')
    
    required_columns = ['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'ã‚³ã‚¹ãƒˆ', 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢', 'ãƒšãƒ¼ã‚¸æœ€ä¸Šéƒ¨ã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢']
    
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        return None, None, f"âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}ã€‚åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ : {df.columns.tolist()}"

    # ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°
    for col in required_columns:
        if df[col].dtype == 'object':
            df[col] = df[col].astype(str).str.replace('%', '', regex=False).str.replace(',', '', regex=False)
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df.dropna(subset=required_columns, inplace=True)
    log_messages.append("âœ… ãƒ‡ãƒ¼ã‚¿å‹ã®ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã¨æ¬ æå€¤ã®é™¤å»ã‚’è¡Œã„ã¾ã—ãŸã€‚")

    # å¤–ã‚Œå€¤ã®é™¤å» (ã‚³ã‚¹ãƒˆã«åŸºã¥ã„ã¦IQRæ³•ã‚’é©ç”¨)
    Q1, Q3 = df['ã‚³ã‚¹ãƒˆ'].quantile(0.25), df['ã‚³ã‚¹ãƒˆ'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
    original_rows = len(df)
    df_cleaned = df[(df['ã‚³ã‚¹ãƒˆ'] >= lower_bound) & (df['ã‚³ã‚¹ãƒˆ'] <= upper_bound)].copy()
    log_messages.append(f"âœ… å¤–ã‚Œå€¤ã‚’é™¤å»ã—ã¾ã—ãŸã€‚(å…ƒã®ãƒ‡ãƒ¼ã‚¿æ•°: {original_rows}, é™¤å»å¾Œ: {len(df_cleaned)})")

    if len(df_cleaned) < 20: # å®‰å®šã—ãŸå­¦ç¿’ã®ãŸã‚ã€æœ€ä½ãƒ‡ãƒ¼ã‚¿æ•°ã‚’å°‘ã—å¢—ã‚„ã™
        return None, None, "âŒ å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ï¼ˆ20ä»¶æœªæº€ï¼‰ã€‚ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã®ã‚ã‚‹CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
    
    log_messages.append("âœ… ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    return df_cleaned, log_messages, None

@st.cache_resource
def train_models(_df_cleaned):
    """
    ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã¨ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã‚‹é–¢æ•°ã€‚
    - ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«: ã‚³ã‚¹ãƒˆã‹ã‚‰å„ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™ã‚’äºˆæ¸¬ (LightGBM)
    - ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: ã‚³ã‚¹ãƒˆã¨å„æŒ‡æ¨™ã‹ã‚‰ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°ã‚’äºˆæ¸¬ (LightGBM - Poisson)
    """
    # â˜…æ”¹å–„ç‚¹: å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿å‘ã‘ã«ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚‚èª¿æ•´
    sub_model_params = {
        'objective': 'regression_l1',
        'random_state': 42,
        'n_estimators': 100,
        'learning_rate': 0.1,
        'num_leaves': 10, # è¤‡é›‘ã•ã‚’æŠ‘ãˆã‚‹
        'n_jobs': -1
    }

    # 1. ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ (ã‚³ã‚¹ãƒˆã‹ã‚‰å„æŒ‡æ¨™ã‚’äºˆæ¸¬)
    features_for_sub_models = ['ã‚³ã‚¹ãƒˆ']
    sub_models = {}
    dependent_features = ['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢', 'ãƒšãƒ¼ã‚¸æœ€ä¸Šéƒ¨ã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢']
    
    for feature in dependent_features:
        X_sub, y_sub, weights_sub = _df_cleaned[features_for_sub_models], _df_cleaned[feature], _df_cleaned['weight']
        sub_model = lgb.LGBMRegressor(**sub_model_params)
        sub_model.fit(X_sub, y_sub, sample_weight=weights_sub)
        sub_models[feature] = sub_model

    # 2. ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ (ã‚³ã‚¹ãƒˆã¨äºˆæ¸¬ã—ãŸæŒ‡æ¨™ã‹ã‚‰CVæ•°ã‚’äºˆæ¸¬)
    main_features = ['ã‚³ã‚¹ãƒˆ'] + dependent_features
    target = 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'
    X_main, y_main, weights_main = _df_cleaned[main_features], _df_cleaned[target], _df_cleaned['weight']

    # â˜…æ”¹å–„ç‚¹: å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆå‘ã‘ã«éå­¦ç¿’ã‚’æŠ‘åˆ¶ã™ã‚‹ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’è¿½åŠ 
    main_model = lgb.LGBMRegressor(
        objective='poisson',      # ã‚«ã‚¦ãƒ³ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’æ‰±ã†ãŸã‚ã®ãƒã‚¢ã‚½ãƒ³å›å¸°
        random_state=42,
        n_estimators=100,         # æœ¨ã®æ•°
        learning_rate=0.1,        # å­¦ç¿’ç‡
        # --- éå­¦ç¿’æŠ‘åˆ¶ã®ãŸã‚ã®ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ ---
        num_leaves=10,            # è‘‰ã®æ•°ã‚’æ¸›ã‚‰ã—ã¦ãƒ¢ãƒ‡ãƒ«ã‚’å˜ç´”åŒ– (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: 31)
        max_depth=7,              # æœ¨ã®æœ€å¤§æ·±åº¦ã‚’åˆ¶é™
        reg_alpha=0.1,            # L1æ­£å‰‡åŒ–
        reg_lambda=0.1,           # L2æ­£å‰‡åŒ–
        colsample_bytree=0.8,     # æœ¨ã‚’æ§‹ç¯‰ã™ã‚‹éš›ã«ç‰¹å¾´é‡ã‚’80%ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        subsample=0.8,            # ãƒ‡ãƒ¼ã‚¿ã‚’80%ã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
        n_jobs=-1                 # CPUã‚³ã‚¢ã‚’ã™ã¹ã¦ä½¿ç”¨
    )
    main_model.fit(X_main, y_main, sample_weight=weights_main)

    # ç‰¹å¾´é‡é‡è¦åº¦ã‚’è¨ˆç®—
    feature_importance = pd.DataFrame({
        'ç‰¹å¾´é‡': X_main.columns,
        'é‡è¦åº¦': main_model.feature_importances_
    }).sort_values('é‡è¦åº¦', ascending=False)

    return sub_models, main_model, feature_importance

def run_simulation(df_cleaned, sub_models, main_model, input_budget):
    """
    æŒ‡å®šã•ã‚ŒãŸäºˆç®—ç¯„å›²ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€çµæœã‚’DataFrameã§è¿”ã™ã€‚
    """
    min_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].min()
    max_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].max()
    
    # ã‚°ãƒ©ãƒ•ã®æç”»ç¯„å›²ã‚’èª¿æ•´
    graph_max_cost = max(max_cost_data, input_budget) * 1.2
    num_steps = 200 # ã‚°ãƒ©ãƒ•ã®æ»‘ã‚‰ã‹ã•ã‚’ä¿ã¤ãŸã‚ã®ã‚¹ãƒ†ãƒƒãƒ—æ•°
    cost_range = np.linspace(min_cost_data, graph_max_cost, num_steps)
    
    sim_results = []
    main_features = ['ã‚³ã‚¹ãƒˆ'] + list(sub_models.keys())

    for cost in cost_range:
        sim_data = {'ã‚³ã‚¹ãƒˆ': cost}
        # ã‚µãƒ–ãƒ¢ãƒ‡ãƒ«ã§å„æŒ‡æ¨™ã‚’äºˆæ¸¬
        for feature, model in sub_models.items():
            sim_data[feature] = model.predict(pd.DataFrame({'ã‚³ã‚¹ãƒˆ': [cost]}))[0]
        
        sim_df_row = pd.DataFrame([sim_data])
        # ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã§CVæ•°ã‚’äºˆæ¸¬
        predicted_cv = main_model.predict(sim_df_row[main_features])[0]
        
        sim_results.append({'ã‚³ã‚¹ãƒˆ': cost, 'äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°': predicted_cv})

    sim_df = pd.DataFrame(sim_results)
    sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] = sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'].clip(lower=0)
    # CPAã‚’è¨ˆç®— (CVæ•°ãŒæ¥µå°ã®å ´åˆã¯è¨ˆç®—ä¸å¯ã¨ã™ã‚‹)
    sim_df['äºˆæ¸¬CPA'] = sim_df.apply(lambda r: r['ã‚³ã‚¹ãƒˆ'] / r['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] if r['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] > 0.01 else np.nan, axis=1)
    
    sim_df.dropna(subset=['äºˆæ¸¬CPA'], inplace=True)
    return sim_df

def create_plot(sim_df, input_budget, predicted_cv, predicted_cpa):
    """
    ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’å¯è¦–åŒ–ã™ã‚‹ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    """
    fig, ax1 = plt.subplots(figsize=(12, 7))
    
    # 1è»¸ç›®: äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°
    color = 'royalblue'
    ax1.set_xlabel('äºˆç®—ï¼ˆã‚³ã‚¹ãƒˆï¼‰[å††]', fontsize=14)
    ax1.set_ylabel('äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', fontsize=14, color=color)
    ax1.plot(sim_df['ã‚³ã‚¹ãƒˆ'], sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'], linestyle='-', color=color, label='äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', linewidth=2.5)
    ax1.tick_params(axis='y', labelcolor=color)
    ax1.grid(True, which='both', linestyle='--', linewidth=0.5)

    # 2è»¸ç›®: äºˆæ¸¬CPA
    ax2 = ax1.twinx()
    color = 'mediumseagreen'
    ax2.set_ylabel('äºˆæ¸¬CPA [å††]', fontsize=14, color=color)
    ax2.plot(sim_df['ã‚³ã‚¹ãƒˆ'], sim_df['äºˆæ¸¬CPA'], linestyle='--', color=color, label='äºˆæ¸¬CPA', linewidth=2.5)
    ax2.tick_params(axis='y', labelcolor=color)

    # å…¥åŠ›ã•ã‚ŒãŸäºˆç®—ã®ãƒ—ãƒ­ãƒƒãƒˆ
    if predicted_cv is not None and predicted_cpa is not None:
        ax1.axvline(x=input_budget, color='tomato', linestyle=':', linewidth=2, label=f"å…¥åŠ›äºˆç®—: {input_budget:,.0f}å††")
        ax1.plot(input_budget, predicted_cv, 'o', color='tomato', markersize=10, markeredgecolor='white', markeredgewidth=1.5)
        ax2.plot(input_budget, predicted_cpa, 'o', color='tomato', markersize=10, markeredgecolor='white', markeredgewidth=1.5)

    # å‡¡ä¾‹ã‚’ã¾ã¨ã‚ã‚‹
    lines, labels = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines + lines2, labels + labels2, loc='upper left', fontsize=12, frameon=True, shadow=True)
    
    fig.tight_layout()
    return fig


# ============== UI: ã‚µã‚¤ãƒ‰ãƒãƒ¼ ==============
with st.sidebar:
    st.markdown("## âš™ï¸ è¨­å®šãƒ‘ãƒãƒ«")
    
    with st.expander("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=True):
        uploaded_file_all = st.file_uploader(
            "1. å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿ (CSV)", 
            type="csv",
            help="éå»ã®å…¨ã¦ã®åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )
        uploaded_file_30d = st.file_uploader(
            "2. ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ (CSV)", 
            type="csv",
            help="äºˆæ¸¬ã§ç‰¹ã«é‡è¦–ã—ãŸã„ç›´è¿‘æœŸé–“ï¼ˆä¾‹: éå»30æ—¥é–“ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )

    st.markdown("---")
    st.markdown("## äºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    input_budget = st.number_input(
        "äºˆæ¸¬ã—ãŸã„äºˆç®—ï¼ˆå††ï¼‰ã‚’å…¥åŠ›", 
        min_value=0, 
        value=None, 
        placeholder="ä¾‹: 50000", 
        step=1000, 
        help="ä»»æ„ã®äºˆç®—é¡ã‚’å††å˜ä½ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    
    recommendation_placeholder = st.empty()


# ============== UI: ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ ==============
st.title('ğŸ› ï¸ CPAäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« v2.1')
st.markdown("éå»ã®åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æœ€é©ãªåºƒå‘Šäºˆç®—ã‚’è¦‹ã¤ã‘å‡ºã—ã¾ã—ã‚‡ã†ã€‚**å°è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ã«æœ€é©åŒ–ã•ã‚ŒãŸãƒ¢ãƒ‡ãƒ«**ã§ã€ã‚ˆã‚Šå®‰å®šã—ãŸäºˆæ¸¬ã‚’æä¾›ã—ã¾ã™ã€‚")

with st.expander("ğŸ’¡ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰"):
    st.markdown("""
    1.  **ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™**: `ã‚³ã‚¹ãƒˆ`, `ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°`ãªã©ã€æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’2ç¨®é¡ï¼ˆå…¨æœŸé–“ãƒ»ç›´è¿‘ï¼‰ç”¨æ„ã—ã¾ã™ã€‚
    2.  **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€ç”¨æ„ã—ãŸ2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    3.  **äºˆç®—ã®å…¥åŠ›**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œäºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã€äºˆæ¸¬ã—ãŸã„äºˆç®—é¡ã‚’å…¥åŠ›ã—ã¾ã™ã€‚
    4.  **çµæœã®ç¢ºèª**: å…¥åŠ›å¾Œã€å³åº§ã«äºˆæ¸¬çµæœãŒãƒ¡ã‚¤ãƒ³ç”»é¢ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã‚°ãƒ©ãƒ•ã‚„è©³ç´°æƒ…å ±ã‚’ç¢ºèªã—ã€äºˆç®—è¨ˆç”»ã®å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚
    """)

st.markdown("---")

# ============== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==============
if uploaded_file_all and uploaded_file_30d:
    with st.spinner('ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ä¸­ã§ã™...'):
        df_cleaned, log_messages, error_message = load_and_preprocess_data(uploaded_file_all, uploaded_file_30d)

    if error_message:
        st.error(error_message)
    else:
        min_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].min()
        max_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].max()
        
        # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«æ¨å¥¨äºˆç®—ç¯„å›²ã‚’è¡¨ç¤º
        with recommendation_placeholder.container():
            st.markdown("##### **æ¨å¥¨äºˆç®—ç¯„å›²**")
            st.success(f"{min_cost_data:,.0f} å†† ã€œ {max_cost_data:,.0f} å††")
            st.caption("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸã€äºˆæ¸¬ç²¾åº¦ãŒæ¯”è¼ƒçš„å®‰å®šã—ã¦ã„ã‚‹ç¯„å›²ã§ã™ã€‚")

        with st.spinner('äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­ã§ã™...'):
            sub_models, main_model, feature_importance = train_models(df_cleaned)

        if input_budget is not None and input_budget > 0:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸäºˆç®—ã§äºˆæ¸¬ã‚’å®Ÿè¡Œ
            sim_data_user = {'ã‚³ã‚¹ãƒˆ': float(input_budget)}
            for feature, model in sub_models.items():
                sim_data_user[feature] = model.predict(pd.DataFrame({'ã‚³ã‚¹ãƒˆ': [input_budget]}))[0]
            
            sim_df_user_row = pd.DataFrame([sim_data_user])
            main_features = ['ã‚³ã‚¹ãƒˆ'] + list(sub_models.keys())
            predicted_cv_user = main_model.predict(sim_df_user_row[main_features])[0]
            predicted_cv_user = max(0, predicted_cv_user) # å¿µã®ãŸã‚è² ã®å€¤ã¯ã‚¯ãƒªãƒƒãƒ—
            predicted_cpa_user = input_budget / predicted_cv_user if predicted_cv_user > 0.01 else float('inf')
            
            st.markdown(f"### äºˆç®— **{input_budget:,.0f}å††** ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
            
            if input_budget > max_cost_data * 1.1: # è­¦å‘Šã®é–¾å€¤ã‚’å°‘ã—ç·©å’Œ
                st.warning(f"âš ï¸ **è­¦å‘Š:** å…¥åŠ›ã•ã‚ŒãŸäºˆç®—ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§ã‚³ã‚¹ãƒˆ ({max_cost_data:,.0f}å††) ã‚’å¤§ããè¶…ãˆã¦ã„ã¾ã™ã€‚äºˆæ¸¬ã¯å¤–æŒ¿ã§ã‚ã‚Šã€ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            col1, col2 = st.columns(2)
            with col1:
                st.metric(label="ğŸ¯ äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°", value=f"{predicted_cv_user:.2f} ä»¶")
            with col2:
                cpa_display = f"{predicted_cpa_user:,.0f} å††" if predicted_cpa_user != float('inf') else "ç®—å‡ºä¸å¯"
                st.metric(label="ğŸ’° äºˆæ¸¬CPA", value=cpa_display)

            with st.spinner('ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆä¸­ã§ã™...'):
                sim_df = run_simulation(df_cleaned, sub_models, main_model, input_budget)
                fig = create_plot(sim_df, input_budget, predicted_cv_user, predicted_cpa_user)
            
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š **äºˆæ¸¬çµæœã®å…¨ä½“åƒã‚°ãƒ©ãƒ•**", "ğŸ§  **ãƒ¢ãƒ‡ãƒ«ã®åˆ†ææƒ…å ±**", "ğŸ“„ **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©³ç´°**"])

            with tab1:
                st.pyplot(fig)
            with tab2:
                st.markdown("#### ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦")
                st.markdown("ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ï¼ˆã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°äºˆæ¸¬ï¼‰ãŒã€ã©ã®æŒ‡æ¨™ã‚’é‡è¦–ã—ã¦äºˆæ¸¬ã‚’è¡Œã£ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚å€¤ãŒå¤§ãã„ã»ã©ã€äºˆæ¸¬ã¸ã®å½±éŸ¿ãŒå¤§ãããªã‚Šã¾ã™ã€‚")
                st.dataframe(feature_importance.style.background_gradient(cmap='viridis', subset=['é‡è¦åº¦']))
                st.markdown("---")
                st.markdown("#### ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚°")
                st.code("\n".join(log_messages))
            with tab3:
                st.markdown("ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆå¤–ã‚Œå€¤é™¤å»å¾Œï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚")
                st.dataframe(df_cleaned.head(100))
                
        else:
            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§äºˆç®—ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

else:
    st.info('ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‹ã‚‰ã€åˆ†æç”¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’2ã¤ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚')
