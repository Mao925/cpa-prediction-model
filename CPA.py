# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import japanize_matplotlib
import warnings
import io
from pytrends.request import TrendReq

# è­¦å‘Šã‚’éè¡¨ç¤ºã«ã™ã‚‹
warnings.filterwarnings('ignore')

# Matplotlibã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®š
plt.style.use('seaborn-v0_8-whitegrid')

# ============== Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIè¨­å®š ==============
st.set_page_config(
    page_title="CPAäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« (Googleãƒˆãƒ¬ãƒ³ãƒ‰å¯¾å¿œç‰ˆ)",
    page_icon="ğŸ“ˆ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ã‚«ã‚¹ã‚¿ãƒ CSSã§è¦‹ãŸç›®ã‚’èª¿æ•´ ---
st.markdown("""
<style>
    .stMetric {
        border-radius: 10px;
        padding: 15px;
        background-color: #f0f2f6;
    }
    .st-emotion-cache-1r4qj8v {
        border-radius: 10px;
    }
</style>
""", unsafe_allow_html=True)


# ============== é–¢æ•°ã®å®šç¾© ==============

@st.cache_data
def load_and_preprocess_data(file_all, file_30d):
    if file_all is None or file_30d is None:
        return None, None, "ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰2ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
    log_messages = []
    def read_csv_robust(file):
        encodings = ['shift_jis', 'cp932', 'utf-8']
        file.seek(0)
        for encoding in encodings:
            try:
                return pd.read_csv(file, encoding=encoding)
            except UnicodeDecodeError:
                file.seek(0)
                continue
        raise UnicodeDecodeError(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.name}' ã‚’ã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚‚èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    try:
        df_all = read_csv_robust(file_all)
        df_30d = read_csv_robust(file_30d)
        log_messages.append("âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
    except Exception as e:
        return None, None, f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"
    
    df_all['weight'] = 1.0
    df_30d['weight'] = 2.0
    log_messages.append(f"âœ… ãƒ¢ãƒ‡ãƒ«ãŒç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿({file_30d.name})ã‚’é‡è¦–ã™ã‚‹ã‚ˆã†ã«ã€é‡ã¿ã‚’2.0ã«èª¿æ•´ã—ã¾ã—ãŸã€‚")
    df = pd.concat([df_all, df_30d], ignore_index=True)
    df.columns = df.columns.str.replace(' ', '').str.replace('ã€€', '')

    if 'æ—¥' not in df.columns:
        return None, None, "âŒ å¿…è¦ãªã‚«ãƒ©ãƒ  'æ—¥' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚CSVã« `YYYY-MM-DD` å½¢å¼ã® 'æ—¥' ã‚«ãƒ©ãƒ ã‚’è¿½åŠ ã—ã¦ãã ã•ã„ã€‚"
    df['æ—¥'] = pd.to_datetime(df['æ—¥'], errors='coerce')
    df.dropna(subset=['æ—¥'], inplace=True)
    log_messages.append("âœ… æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’èªè­˜ã—ã¾ã—ãŸã€‚")

    try:
        pytrends = TrendReq(hl='ja-JP', tz=540)
        kw_list = ["å¡¾è¬›å¸« ãƒã‚¤ãƒˆ", "å¡¾ ãƒã‚¤ãƒˆ"]
        start_date = df['æ—¥'].min().strftime('%Y-%m-%d')
        end_date = df['æ—¥'].max().strftime('%Y-%m-%d')
        timeframe = f'{start_date} {end_date}'
        pytrends.build_payload(kw_list, cat=0, timeframe=timeframe, geo='JP', gprop='')
        trends_df = pytrends.interest_over_time()

        if trends_df.empty or 'isPartial' in trends_df.columns and trends_df['isPartial'].any():
             log_messages.append("âš ï¸ Googleãƒˆãƒ¬ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿ãŒå–å¾—ã§ããªã„ã‹ã€ä¸å®Œå…¨ã§ã—ãŸã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤(50)ã§è£œå®Œã—ã¾ã™ã€‚")
             df['google_trend'] = 50
        else:
            trends_df['google_trend'] = trends_df[kw_list].mean(axis=1)
            trends_df = trends_df.reset_index().rename(columns={'date': 'æ—¥'})
            trends_df = trends_df[['æ—¥', 'google_trend']]
            trends_df['æ—¥'] = pd.to_datetime(trends_df['æ—¥'])
            df = pd.merge(df, trends_df, on='æ—¥', how='left')
            df['google_trend'].fillna(method='ffill', inplace=True)
            df['google_trend'].fillna(method='bfill', inplace=True)
            log_messages.append(f"âœ… Googleãƒˆãƒ¬ãƒ³ãƒ‰ã®ãƒ‡ãƒ¼ã‚¿({', '.join(kw_list)})ã‚’å–å¾—ã—ã€å¹³å‡å€¤ã‚’çµåˆã—ã¾ã—ãŸã€‚")

    except Exception as e:
        log_messages.append(f"âš ï¸ Googleãƒˆãƒ¬ãƒ³ãƒ‰ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ ({e})ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤(50)ã§è£œå®Œã—ã¾ã™ã€‚")
        df['google_trend'] = 50

    required_columns = ['æ—¥', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'ã‚¯ãƒªãƒƒã‚¯ç‡', 'ã‚³ã‚¹ãƒˆ', 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢', 'ãƒšãƒ¼ã‚¸æœ€ä¸Šéƒ¨ã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢', 'google_trend']
    required_columns_with_weight = required_columns + ['weight']
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        return None, None, f"âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}ã€‚åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ : {df.columns.tolist()}"
    
    for col in [c for c in required_columns if c not in ['æ—¥', 'google_trend']]:
        if df[col].dtype == 'object':
            df[col] = df[col].astype(str).str.replace('%', '', regex=False).str.replace(',', '', regex=False)
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df.dropna(subset=required_columns_with_weight, inplace=True)
    log_messages.append("âœ… ãƒ‡ãƒ¼ã‚¿å‹ã®ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã¨æ¬ æå€¤ã®é™¤å»ã‚’è¡Œã„ã¾ã—ãŸã€‚")
    Q1, Q3 = df['ã‚³ã‚¹ãƒˆ'].quantile(0.25), df['ã‚³ã‚¹ãƒˆ'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
    original_rows = len(df)
    df_cleaned = df[(df['ã‚³ã‚¹ãƒˆ'] >= lower_bound) & (df['ã‚³ã‚¹ãƒˆ'] <= upper_bound)].copy()
    log_messages.append(f"âœ… å¤–ã‚Œå€¤ã‚’é™¤å»ã—ã¾ã—ãŸã€‚(å…ƒã®ãƒ‡ãƒ¼ã‚¿æ•°: {original_rows}, é™¤å»å¾Œ: {len(df_cleaned)})")
    if len(df_cleaned) < 10:
         return None, None, "âŒ å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ã€‚ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã®ã‚ã‚‹CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
    log_messages.append("âœ… ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    return df_cleaned, log_messages, None

@st.cache_resource
def train_models(_df_cleaned):
    features_for_sub_models = ['ã‚³ã‚¹ãƒˆ', 'google_trend']
    sub_models = {}
    dependent_features = ['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢', 'ãƒšãƒ¼ã‚¸æœ€ä¸Šéƒ¨ã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢']
    for feature in dependent_features:
        X_sub, y_sub, weights_sub = _df_cleaned[features_for_sub_models], _df_cleaned[feature], _df_cleaned['weight']
        sub_model = lgb.LGBMRegressor(random_state=42, objective='regression_l1')
        sub_model.fit(X_sub, y_sub, sample_weight=weights_sub)
        sub_models[feature] = sub_model
    main_features = ['ã‚³ã‚¹ãƒˆ', 'google_trend'] + dependent_features
    target = 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'
    X_main, y_main, weights_main = _df_cleaned[main_features], _df_cleaned[target], _df_cleaned['weight']
    main_model = LinearRegression()
    main_model.fit(X_main, y_main, sample_weight=weights_main)
    coefficients = pd.DataFrame(main_model.coef_, X_main.columns, columns=['å›å¸°ä¿‚æ•°'])
    return sub_models, main_model, coefficients

def run_simulation(df_cleaned, sub_models, main_model, input_budget, input_trend):
    min_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].min()
    max_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].max()
    graph_max_cost = max(max_cost_data, input_budget) * 1.1
    num_steps = max(200, int((graph_max_cost - min_cost_data) / 1000))
    cost_range = np.linspace(min_cost_data, graph_max_cost, num_steps)
    sim_results = []
    main_features = ['ã‚³ã‚¹ãƒˆ', 'google_trend'] + list(sub_models.keys())
    for cost in cost_range:
        sim_data = {'ã‚³ã‚¹ãƒˆ': cost, 'google_trend': input_trend}
        for feature, model in sub_models.items():
            predict_df = pd.DataFrame({'ã‚³ã‚¹ãƒˆ': [cost], 'google_trend': [input_trend]})
            sim_data[feature] = model.predict(predict_df)[0]
        sim_df_row = pd.DataFrame([sim_data])
        predicted_cv = main_model.predict(sim_df_row[main_features])[0]
        sim_results.append({'ã‚³ã‚¹ãƒˆ': cost, 'äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°': predicted_cv})
    sim_df = pd.DataFrame(sim_results)
    sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] = sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'].clip(lower=0)
    sim_df['äºˆæ¸¬CPA'] = sim_df.apply(lambda r: r['ã‚³ã‚¹ãƒˆ'] / r['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] if r['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] > 0.01 else np.nan, axis=1)
    sim_df.dropna(subset=['äºˆæ¸¬CPA'], inplace=True)
    return sim_df

# ### å¤‰æ›´ ### : ã‚°ãƒ©ãƒ•æç”»é–¢æ•°ã«æœ€é©ç‚¹ã®å¼•æ•°ã‚’è¿½åŠ 
def create_plot(sim_df, input_budget, predicted_cv, predicted_cpa, optimal_budget=None, optimal_cv=None, optimal_cpa=None):
    fig, ax1 = plt.subplots(figsize=(12, 7))
    color = 'royalblue'
    ax1.set_xlabel('äºˆç®—ï¼ˆã‚³ã‚¹ãƒˆï¼‰[å††]', fontsize=14)
    ax1.set_ylabel('äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', fontsize=14, color=color)
    ax1.plot(sim_df['ã‚³ã‚¹ãƒˆ'], sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'], linestyle='-', color=color, label='äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', linewidth=2.5)
    ax1.tick_params(axis='y', labelcolor=color)
    ax1.grid(True, which='both', linestyle='--', linewidth=0.5)
    ax2 = ax1.twinx()
    color = 'mediumseagreen'
    ax2.set_ylabel('äºˆæ¸¬CPA [å††]', fontsize=14, color=color)
    ax2.plot(sim_df['ã‚³ã‚¹ãƒˆ'], sim_df['äºˆæ¸¬CPA'], linestyle='--', color=color, label='äºˆæ¸¬CPA', linewidth=2.5)
    ax2.tick_params(axis='y', labelcolor=color)
    
    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã®äºˆç®—ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    if predicted_cv is not None and predicted_cpa is not None:
        ax1.axvline(x=input_budget, color='tomato', linestyle=':', linewidth=2, label=f"å…¥åŠ›äºˆç®—: {input_budget:,.0f}å††")
        ax1.plot(input_budget, predicted_cv, 'o', color='tomato', markersize=10, markeredgecolor='white', markeredgewidth=1.5)
        ax2.plot(input_budget, predicted_cpa, 'o', color='tomato', markersize=10, markeredgecolor='white', markeredgewidth=1.5)

    # ### è¿½åŠ  ### : æœ€é©äºˆç®—ã®ç‚¹ã‚’ãƒ—ãƒ­ãƒƒãƒˆ
    if optimal_budget is not None:
        ax1.axvline(x=optimal_budget, color='gold', linestyle=':', linewidth=2, label=f"æœ€é©äºˆç®—: {optimal_budget:,.0f}å††")
        ax1.plot(optimal_budget, optimal_cv, 'o', color='gold', markersize=10, markeredgecolor='black', markeredgewidth=1.5)
        ax2.plot(optimal_budget, optimal_cpa, 'o', color='gold', markersize=10, markeredgecolor='black', markeredgewidth=1.5)

    lines, labels = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines + lines2, labels + labels2, loc='upper left', fontsize=12, frameon=True, shadow=True)
    fig.tight_layout()
    return fig


# ============== UI: ã‚µã‚¤ãƒ‰ãƒãƒ¼ ==============
with st.sidebar:
    st.markdown("## âš™ï¸ è¨­å®šãƒ‘ãƒãƒ«")
    with st.expander("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=True):
        uploaded_file_all = st.file_uploader(
            "1. å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿ (CSV)",
            type="csv",
            help="éå»ã®å…¨ã¦ã®åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚`æ—¥`ã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™ã€‚"
        )
        uploaded_file_30d = st.file_uploader(
            "2. ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ (CSV)",
            type="csv",
            help="äºˆæ¸¬ã§ç‰¹ã«é‡è¦–ã—ãŸã„ç›´è¿‘æœŸé–“ï¼ˆä¾‹: éå»30æ—¥é–“ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚`æ—¥`ã‚«ãƒ©ãƒ ãŒå¿…è¦ã§ã™ã€‚"
        )
    st.markdown("---")
    st.markdown("## äºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    input_budget = st.number_input(
        "äºˆæ¸¬ã—ãŸã„äºˆç®—ï¼ˆå††ï¼‰ã‚’å…¥åŠ›",
        min_value=0,
        value=None,
        placeholder="ä¾‹: 50000",
        step=1000,
        help="ä»»æ„ã®äºˆç®—é¡ã‚’å††å˜ä½ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    st.markdown("## å¤–éƒ¨è¦å› ã®è¨­å®š")
    input_trend = st.slider(
        "ğŸ“ˆ å°†æ¥ã®ãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ•° (ä»»æ„)",
        min_value=0,
        max_value=100,
        value=50,
        help="ã€Œå¡¾è¬›å¸« ãƒã‚¤ãƒˆã€ã€Œå¡¾ ãƒã‚¤ãƒˆã€ã®Googleãƒˆãƒ¬ãƒ³ãƒ‰æ¤œç´¢æ•°ã‚’æƒ³å®šã—ã¦è¨­å®šã—ã¾ã™ã€‚100ãŒæœ€å¤§é–¢å¿ƒæ™‚ã§ã™ã€‚"
    )
    recommendation_placeholder = st.empty()


# ============== UI: ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ ==============
st.title('ğŸ“ˆ CPAäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« (Googleãƒˆãƒ¬ãƒ³ãƒ‰å¯¾å¿œç‰ˆ)')
st.markdown("éå»ã®åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã¨Googleãƒˆãƒ¬ãƒ³ãƒ‰ã®æ¤œç´¢é‡ã‚’å…ƒã«ã€æœ€é©ãªåºƒå‘Šäºˆç®—ã‚’è¦‹ã¤ã‘å‡ºã—ã¾ã—ã‚‡ã†ã€‚")

with st.expander("ğŸ’¡ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰"):
    st.markdown("""
    1.  **ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™**: `ã‚³ã‚¹ãƒˆ`, `ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°`ãªã©ã«åŠ ãˆã€`YYYY-MM-DD`å½¢å¼ã®**`æ—¥`**ã‚«ãƒ©ãƒ ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’2ç¨®é¡ï¼ˆå…¨æœŸé–“ãƒ»ç›´è¿‘ï¼‰ç”¨æ„ã—ã¾ã™ã€‚
    2.  **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€ç”¨æ„ã—ãŸ2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    3.  **æ¡ä»¶ã®è¨­å®š**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§ã€äºˆæ¸¬ã—ãŸã„ã€Œäºˆç®—ã€ã¨ã€å°†æ¥ã®ã€Œãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ•°ã€ã‚’ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã§è¨­å®šã—ã¾ã™ã€‚
    4.  **çµæœã®ç¢ºèª**: å…¥åŠ›å¾Œã€å³åº§ã«äºˆæ¸¬çµæœãŒãƒ¡ã‚¤ãƒ³ç”»é¢ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚**ã‚ãªãŸã®è¨­å®šã—ãŸäºˆç®—ã§ã®äºˆæ¸¬**ã¨ã€**è²»ç”¨å¯¾åŠ¹æœãŒæœ€ã‚‚è‰¯ã„ã€Œæœ€é©äºˆç®—ã€**ãŒææ¡ˆã•ã‚Œã¾ã™ã€‚
    """)
st.markdown("---")

# ============== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==============
if uploaded_file_all and uploaded_file_30d:
    with st.spinner('ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ä¸­ã§ã™...'):
        df_cleaned, log_messages, error_message = load_and_preprocess_data(uploaded_file_all, uploaded_file_30d)

    if error_message:
        st.error(error_message)
    else:
        min_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].min()
        max_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].max()
        with recommendation_placeholder.container():
            st.markdown("##### **æ¨å¥¨äºˆç®—ç¯„å›²**")
            st.info(f"{min_cost_data:,.0f} å†† ã€œ {max_cost_data:,.0f} å††")
            st.caption("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸã€äºˆæ¸¬ç²¾åº¦ãŒæ¯”è¼ƒçš„å®‰å®šã—ã¦ã„ã‚‹ç¯„å›²ã§ã™ã€‚")

        with st.spinner('äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­ã§ã™...'):
            sub_models, main_model, coefficients = train_models(df_cleaned)

        if input_budget is not None and input_budget > 0:
            # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›äºˆç®—ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
            sim_data_user = {'ã‚³ã‚¹ãƒˆ': float(input_budget), 'google_trend': float(input_trend)}
            for feature, model in sub_models.items():
                predict_df = pd.DataFrame({'ã‚³ã‚¹ãƒˆ': [input_budget], 'google_trend': [input_trend]})
                sim_data_user[feature] = model.predict(predict_df)[0]
            
            sim_df_user_row = pd.DataFrame([sim_data_user])
            main_features = ['ã‚³ã‚¹ãƒˆ', 'google_trend'] + list(sub_models.keys())
            predicted_cv_user = main_model.predict(sim_df_user_row[main_features])[0]
            predicted_cv_user = max(0, predicted_cv_user)
            predicted_cpa_user = input_budget / predicted_cv_user if predicted_cv_user > 0.01 else float('inf')
            
            st.markdown(f"### äºˆç®— **{input_budget:,.0f}å††** / ãƒˆãƒ¬ãƒ³ãƒ‰æŒ‡æ•° **{input_trend}** ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
            
            if input_budget > max_cost_data:
                st.warning(f"âš ï¸ **è­¦å‘Š:** å…¥åŠ›ã•ã‚ŒãŸäºˆç®—ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§ã‚³ã‚¹ãƒˆ ({max_cost_data:,.0f}å††) ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚äºˆæ¸¬ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            col1, col2 = st.columns(2)
            with col1:
                st.metric(label="ğŸ¯ äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°", value=f"{predicted_cv_user:.2f} ä»¶")
            with col2:
                cpa_display = f"{predicted_cpa_user:,.0f} å††" if predicted_cpa_user != float('inf') else "ç®—å‡ºä¸å¯"
                st.metric(label="ğŸ’° äºˆæ¸¬CPA", value=cpa_display)
            
            # â–¼â–¼â–¼ã€å‡¦ç†é †åºã‚’ä¿®æ­£ã€‘â–¼â–¼â–¼
            # å…ˆã«å…¨ä½“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã¦sim_dfã‚’ç¢ºå®šã•ã›ã‚‹
            with st.spinner('å…¨ä½“ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨æœ€é©ç‚¹ã®è¨ˆç®—ä¸­ã§ã™...'):
                sim_df = run_simulation(df_cleaned, sub_models, main_model, input_budget, input_trend)
                
                # sim_df ã‚’ä½¿ã£ã¦æœ€é©ç‚¹ã‚’è¨ˆç®—
                optimal_budget, optimal_cv, optimal_cpa = None, None, None
                if not sim_df.empty and 'äºˆæ¸¬CPA' in sim_df.columns:
                    optimal_point = sim_df.loc[sim_df['äºˆæ¸¬CPA'].idxmin()]
                    optimal_budget = optimal_point['ã‚³ã‚¹ãƒˆ']
                    optimal_cv = optimal_point['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°']
                    optimal_cpa = optimal_point['äºˆæ¸¬CPA']
            
            # æœ€é©äºˆç®—ã®ææ¡ˆã‚’è¡¨ç¤º
            st.markdown("---")
            st.markdown("### ğŸ’¡ æœ€é©äºˆç®—ã®ææ¡ˆ")
            if optimal_budget is not None:
                st.success(
                    f"""
                    ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ä¸Šã€æœ€ã‚‚CPAãŒä½ããªã‚‹ï¼ˆè²»ç”¨å¯¾åŠ¹æœãŒé«˜ã„ï¼‰ã®ã¯ **äºˆç®— {optimal_budget:,.0f} å††** ã§ã™ã€‚
                    - **ãã®æ™‚ã®äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°**: {optimal_cv:.2f} ä»¶
                    - **ãã®æ™‚ã®äºˆæ¸¬CPA**: **{optimal_cpa:,.0f} å††**
                    """
                )
            else:
                st.info("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‹ã‚‰æœ€é©äºˆç®—ã‚’ç®—å‡ºã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

            # æœ€å¾Œã«ã€ç¢ºå®šã—ãŸæƒ…å ±ã‚’ä½¿ã£ã¦ã‚°ãƒ©ãƒ•ã‚’æç”»
            fig = create_plot(sim_df, input_budget, predicted_cv_user, predicted_cpa_user, optimal_budget, optimal_cv, optimal_cpa)
            
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š **äºˆæ¸¬çµæœã®å…¨ä½“åƒã‚°ãƒ©ãƒ•**", "ğŸ“„ **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©³ç´°**", "ğŸ§  **ãƒ¢ãƒ‡ãƒ«ã®åˆ†ææƒ…å ±**"])
            # â–²â–²â–²ã€ã“ã“ã¾ã§ä¿®æ­£ã€‘â–²â–²â–²

            with tab1:
                st.pyplot(fig)
            with tab2:
                st.markdown("ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆå¤–ã‚Œå€¤é™¤å»ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰ãƒ‡ãƒ¼ã‚¿çµåˆå¾Œï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚")
                st.dataframe(df_cleaned.head(100))
            with tab3:
                st.markdown("#### é‡å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å›å¸°ä¿‚æ•°")
                st.markdown("å„æŒ‡æ¨™ãŒ1å˜ä½å¢—åŠ ã—ãŸã¨ãã«ã€ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°ãŒã©ã‚Œã ã‘å¢—æ¸›ã™ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚`google_trend`ãŒè¿½åŠ ã•ã‚Œã¦ã„ã¾ã™ã€‚")
                st.table(coefficients.style.format("{:.4f}").background_gradient(cmap='viridis'))
                st.markdown("---")
                st.markdown("#### ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚°")
                st.code("\n".join(log_messages))
        else:
            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§äºˆç®—ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

else:
    st.info('ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‹ã‚‰ã€åˆ†æç”¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’2ã¤ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚')
