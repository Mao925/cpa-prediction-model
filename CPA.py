# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import KFold
from sklearn.metrics import mean_absolute_error
import matplotlib.pyplot as plt
import matplotlib.font_manager
import warnings
import io

# æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
try:
    font_path = matplotlib.font_manager.findfont(matplotlib.font_manager.FontProperties(family='IPAexGothic'))
    if font_path:
        plt.rcParams['font.family'] = 'IPAexGothic'
except:
    st.warning("æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆï¼ˆIPAexGothicï¼‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ã‚°ãƒ©ãƒ•ã®æ—¥æœ¬èªãŒæ–‡å­—åŒ–ã‘ã™ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

# è­¦å‘Šã‚’éè¡¨ç¤ºã«ã™ã‚‹
warnings.filterwarnings('ignore')

# Matplotlibã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®š
plt.style.use('seaborn-v0_8-whitegrid')

# ============== Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIè¨­å®š ==============
st.set_page_config(
    page_title="CPAäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« v3.0",
    page_icon="ğŸ’¡",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ã‚«ã‚¹ã‚¿ãƒ CSSã§è¦‹ãŸç›®ã‚’èª¿æ•´ ---
st.markdown("""
<style>
    .stMetric {
        border-radius: 10px;
        padding: 15px;
        background-color: #f0f2f6;
    }
    .st-emotion-cache-1r4qj8v, .st-emotion-cache-1kyxreq {
        border-radius: 10px;
    }
    .st-emotion-cache-1kyxreq {
        background-color: #e8f0fe; /* æˆ¦ç•¥ãƒ—ãƒ©ãƒ³ã®èƒŒæ™¯è‰² */
        border: 1px solid #1967d2;
    }
</style>
""", unsafe_allow_html=True)


# ============== é–¢æ•°ã®å®šç¾© ==============

@st.cache_data
def load_and_preprocess_data(file, recency_days, recency_weight):
    """
    å˜ä¸€ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€å‰å‡¦ç†ã‚’è¡Œã†é–¢æ•°ã€‚
    - æ—¥ä»˜ã‚«ãƒ©ãƒ ã®è‡ªå‹•èªè­˜
    - ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° (CTR, CVR, CPC)
    - ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã¸ã®é‡ã¿ä»˜ã‘
    - ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã¨å¤–ã‚Œå€¤é™¤å»
    """
    if file is None:
        return None, None, "ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"

    log_messages = []

    def read_csv_robust(f):
        encodings = ['utf-8-sig', 'shift_jis', 'cp932', 'utf-8']
        f.seek(0)
        for encoding in encodings:
            try:
                return pd.read_csv(f, encoding=encoding)
            except UnicodeDecodeError:
                f.seek(0)
                continue
        raise UnicodeDecodeError(f"ãƒ•ã‚¡ã‚¤ãƒ« '{f.name}' ã‚’ã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚‚èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")

    try:
        df = read_csv_robust(file)
        log_messages.append("âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
    except Exception as e:
        return None, None, f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"

    # --- æ—¥ä»˜ã‚«ãƒ©ãƒ ã®è‡ªå‹•èªè­˜ ---
    date_col_candidates = ['æ—¥', 'æ—¥ä»˜', 'Date', 'Day']
    date_col = None
    for col in date_col_candidates:
        if col in df.columns:
            date_col = col
            break
    if not date_col:
        return None, None, f"âŒ æ—¥ä»˜ã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚«ãƒ©ãƒ åã‚’ {', '.join(date_col_candidates)} ã®ã„ãšã‚Œã‹ã«å¤‰æ›´ã—ã¦ãã ã•ã„ã€‚"
    
    try:
        df[date_col] = pd.to_datetime(df[date_col])
        log_messages.append(f"âœ… æ—¥ä»˜ã‚«ãƒ©ãƒ  '{date_col}' ã‚’èªè­˜ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        return None, None, f"âŒ æ—¥ä»˜ã‚«ãƒ©ãƒ  '{date_col}' ã‚’æ—¥ä»˜å½¢å¼ã«å¤‰æ›ã§ãã¾ã›ã‚“ã§ã—ãŸ: {e}"

    # --- ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã¨å‹å¤‰æ› ---
    df.columns = df.columns.str.replace(' ', '').str.replace('ã€€', '')
    required_columns = ['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'ã‚³ã‚¹ãƒˆ', 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°']
    
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        return None, None, f"âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}"

    for col in required_columns:
        if df[col].dtype == 'object':
            df[col] = df[col].astype(str).str.replace('%', '', regex=False).str.replace(',', '', regex=False)
        df[col] = pd.to_numeric(df[col], errors='coerce')

    df.dropna(subset=required_columns, inplace=True)
    log_messages.append("âœ… ãƒ‡ãƒ¼ã‚¿å‹ã®ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã¨æ¬ æå€¤ã®é™¤å»ã‚’è¡Œã„ã¾ã—ãŸã€‚")

    # --- ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚° ---
    df['CTR'] = np.divide(df['ã‚¯ãƒªãƒƒã‚¯æ•°'], df['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°'], out=np.zeros_like(df['ã‚¯ãƒªãƒƒã‚¯æ•°'], dtype=float), where=df['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°']!=0)
    df['CVR'] = np.divide(df['ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'], df['ã‚¯ãƒªãƒƒã‚¯æ•°'], out=np.zeros_like(df['ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'], dtype=float), where=df['ã‚¯ãƒªãƒƒã‚¯æ•°']!=0)
    df['CPC'] = np.divide(df['ã‚³ã‚¹ãƒˆ'], df['ã‚¯ãƒªãƒƒã‚¯æ•°'], out=np.zeros_like(df['ã‚³ã‚¹ãƒˆ'], dtype=float), where=df['ã‚¯ãƒªãƒƒã‚¯æ•°']!=0)
    log_messages.append("âœ… ç‰¹å¾´é‡ï¼ˆCTR, CVR, CPCï¼‰ã‚’ç”Ÿæˆã—ã¾ã—ãŸã€‚")

    # --- é‡ã¿ä»˜ã‘ ---
    latest_date = df[date_col].max()
    df['weight'] = np.where(df[date_col] >= latest_date - pd.Timedelta(days=recency_days), recency_weight, 1.0)
    log_messages.append(f"âœ… ç›´è¿‘{recency_days}æ—¥é–“ã®ãƒ‡ãƒ¼ã‚¿ã«{recency_weight}å€ã®é‡ã¿ã‚’ä»˜ã‘ã¾ã—ãŸã€‚")

    # --- å¤–ã‚Œå€¤é™¤å» ---
    Q1, Q3 = df['ã‚³ã‚¹ãƒˆ'].quantile(0.25), df['ã‚³ã‚¹ãƒˆ'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
    original_rows = len(df)
    df_cleaned = df[(df['ã‚³ã‚¹ãƒˆ'] >= lower_bound) & (df['ã‚³ã‚¹ãƒˆ'] <= upper_bound)].copy()
    log_messages.append(f"âœ… å¤–ã‚Œå€¤ã‚’é™¤å»ã—ã¾ã—ãŸã€‚(å…ƒã®ãƒ‡ãƒ¼ã‚¿æ•°: {original_rows}, é™¤å»å¾Œ: {len(df_cleaned)})")

    if len(df_cleaned) < 30:
        return None, None, "âŒ å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ï¼ˆ30ä»¶æœªæº€ï¼‰ã€‚ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã®ã‚ã‚‹CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
    
    log_messages.append("âœ… ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    return df_cleaned, log_messages, None

@st.cache_resource
def train_and_evaluate_model(_df_cleaned):
    """
    å˜ä¸€ã®LightGBMãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ã•ã›ã€ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã§è©•ä¾¡ã™ã‚‹é–¢æ•°ã€‚
    """
    features = ['ã‚³ã‚¹ãƒˆ', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'CTR', 'CVR', 'CPC']
    # 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢' ãªã©ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§å¤‰å‹•ã•ã›ã‚‰ã‚Œãªã„ã‚‚ã®ã¯ä¸€æ—¦é™¤å¤–
    # å¿…è¦ã§ã‚ã‚Œã°ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã«è¿½åŠ ã™ã‚‹
    target = 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'

    X, y, weights = _df_cleaned[features], _df_cleaned[target], _df_cleaned['weight']

    model_params = {
        'objective': 'poisson',
        'random_state': 42,
        'n_estimators': 100,
        'learning_rate': 0.1,
        'num_leaves': 10,
        'max_depth': 7,
        'reg_alpha': 0.1,
        'reg_lambda': 0.1,
        'colsample_bytree': 0.8,
        'subsample': 0.8,
        'n_jobs': -1
    }
    
    # --- ã‚¯ãƒ­ã‚¹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã«ã‚ˆã‚‹ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ ---
    kf = KFold(n_splits=5, shuffle=True, random_state=42)
    oof_preds = np.zeros(len(_df_cleaned))
    maes = []
    
    for fold, (train_idx, val_idx) in enumerate(kf.split(X, y)):
        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]
        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]
        weights_train = weights.iloc[train_idx]

        model_cv = lgb.LGBMRegressor(**model_params)
        model_cv.fit(X_train, y_train, sample_weight=weights_train)
        
        val_preds = model_cv.predict(X_val)
        maes.append(mean_absolute_error(y_val, val_preds))

    avg_mae = np.mean(maes)

    # --- å…¨ãƒ‡ãƒ¼ã‚¿ã§æœ€çµ‚ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ ---
    final_model = lgb.LGBMRegressor(**model_params)
    final_model.fit(X, y, sample_weight=weights)

    feature_importance = pd.DataFrame({
        'ç‰¹å¾´é‡': X.columns,
        'é‡è¦åº¦': final_model.feature_importances_
    }).sort_values('é‡è¦åº¦', ascending=False)

    return final_model, feature_importance, avg_mae

@st.cache_resource
def create_simulation_models(_df_cleaned):
    """
    ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã‚³ã‚¹ãƒˆã«é€£å‹•ã—ã¦å¤‰å‹•ã™ã‚‹æŒ‡æ¨™ã‚’äºˆæ¸¬ã™ã‚‹ãŸã‚ã®ã€
    å˜ç´”ãªç·šå½¢å›å¸°ãƒ¢ãƒ‡ãƒ«ç¾¤ã‚’ä½œæˆã™ã‚‹ã€‚
    """
    sim_models = {}
    # ã‚³ã‚¹ãƒˆãŒä¸ŠãŒã‚‹ã¨å¤‰å‹•ã™ã‚‹å¯èƒ½æ€§ã®ã‚ã‚‹æŒ‡æ¨™
    sim_target_features = ['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'CPC'] 
    
    for feature in sim_target_features:
        X = _df_cleaned[['ã‚³ã‚¹ãƒˆ']]
        y = _df_cleaned[feature]
        model = LinearRegression()
        model.fit(X, y)
        sim_models[feature] = model
        
    return sim_models

def run_simulation(df_cleaned, main_model, sim_models, input_budget):
    """
    æŒ‡å®šã•ã‚ŒãŸäºˆç®—ç¯„å›²ã§ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œã—ã€çµæœã‚’DataFrameã§è¿”ã™ã€‚
    """
    min_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].min()
    max_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].max()
    
    graph_max_cost = max(max_cost_data, input_budget) * 1.2
    num_steps = 200
    cost_range = np.linspace(min_cost_data, graph_max_cost, num_steps)
    
    sim_results = []

    for cost in cost_range:
        sim_data = {'ã‚³ã‚¹ãƒˆ': cost}
        
        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ¢ãƒ‡ãƒ«ã§å„æŒ‡æ¨™ã‚’äºˆæ¸¬
        for feature, model in sim_models.items():
            sim_data[feature] = model.predict(pd.DataFrame({'ã‚³ã‚¹ãƒˆ': [cost]}))[0]

        # äºˆæ¸¬ã—ãŸæŒ‡æ¨™ã‹ã‚‰ã€ã•ã‚‰ã«ç‰¹å¾´é‡ã‚’è¨ˆç®—
        sim_data['CTR'] = np.divide(sim_data['ã‚¯ãƒªãƒƒã‚¯æ•°'], sim_data['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°'], where=sim_data['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°']!=0)
        # CVRã¯å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¹³å‡å€¤ã‚’ä»®å®šï¼ˆã‚³ã‚¹ãƒˆå¤‰å‹•ã§CVRè‡ªä½“ã¯å¤§ããå¤‰ã‚ã‚‰ãªã„ã¨ä»®å®šï¼‰
        sim_data['CVR'] = df_cleaned['CVR'].mean() 

        sim_df_row = pd.DataFrame([sim_data])
        
        # ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ãŒå­¦ç¿’ã—ãŸç‰¹å¾´é‡ã®é †ç•ªã«åˆã‚ã›ã‚‹
        features_for_prediction = main_model.feature_name_
        
        # ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«ã§CVæ•°ã‚’äºˆæ¸¬
        predicted_cv = main_model.predict(sim_df_row[features_for_prediction])[0]
        
        sim_results.append({'ã‚³ã‚¹ãƒˆ': cost, 'äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°': predicted_cv})

    sim_df = pd.DataFrame(sim_results)
    sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] = sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'].clip(lower=0)
    sim_df['äºˆæ¸¬CPA'] = sim_df.apply(lambda r: r['ã‚³ã‚¹ãƒˆ'] / r['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] if r['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] > 0.01 else np.nan, axis=1)
    
    sim_df.dropna(subset=['äºˆæ¸¬CPA'], inplace=True)
    return sim_df

def create_plot(sim_df, input_budget, predicted_cv, predicted_cpa, cpa_best_point, cv_max_point):
    """
    ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœã‚’å¯è¦–åŒ–ã™ã‚‹ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆã™ã‚‹ã€‚
    æˆ¦ç•¥çš„ãƒã‚¤ãƒ³ãƒˆã‚‚ãƒã‚¤ãƒ©ã‚¤ãƒˆã™ã‚‹ã€‚
    """
    fig, ax1 = plt.subplots(figsize=(12, 7))
    
    # 1è»¸ç›®: äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°
    color = 'royalblue'
    ax1.set_xlabel('äºˆç®—ï¼ˆã‚³ã‚¹ãƒˆï¼‰[å††]', fontsize=14)
    ax1.set_ylabel('äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', fontsize=14, color=color)
    ax1.plot(sim_df['ã‚³ã‚¹ãƒˆ'], sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'], linestyle='-', color=color, label='äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', linewidth=2.5, zorder=10)
    ax1.tick_params(axis='y', labelcolor=color)
    ax1.grid(True, which='both', linestyle='--', linewidth=0.5)

    # 2è»¸ç›®: äºˆæ¸¬CPA
    ax2 = ax1.twinx()
    color = 'mediumseagreen'
    ax2.set_ylabel('äºˆæ¸¬CPA [å††]', fontsize=14, color=color)
    ax2.plot(sim_df['ã‚³ã‚¹ãƒˆ'], sim_df['äºˆæ¸¬CPA'], linestyle='--', color=color, label='äºˆæ¸¬CPA', linewidth=2.5, zorder=10)
    ax2.tick_params(axis='y', labelcolor=color)

    # å…¥åŠ›ã•ã‚ŒãŸäºˆç®—ã®ãƒ—ãƒ­ãƒƒãƒˆ
    if predicted_cv is not None and predicted_cpa is not None:
        ax1.axvline(x=input_budget, color='tomato', linestyle=':', linewidth=2, label=f"å…¥åŠ›äºˆç®—: {input_budget:,.0f}å††", zorder=5)
        ax1.plot(input_budget, predicted_cv, 'o', color='tomato', markersize=10, markeredgecolor='white', markeredgewidth=1.5, zorder=20)
        ax2.plot(input_budget, predicted_cpa, 'o', color='tomato', markersize=10, markeredgecolor='white', markeredgewidth=1.5, zorder=20)

    # æˆ¦ç•¥çš„ãƒã‚¤ãƒ³ãƒˆã®ãƒ—ãƒ­ãƒƒãƒˆ
    if cpa_best_point is not None:
        ax1.plot(cpa_best_point['ã‚³ã‚¹ãƒˆ'], cpa_best_point['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'], 'D', color='gold', markersize=12, markeredgecolor='black', label='CPAæœ€è‰¯åŒ–ç‚¹', zorder=21)
        ax2.plot(cpa_best_point['ã‚³ã‚¹ãƒˆ'], cpa_best_point['äºˆæ¸¬CPA'], 'D', color='gold', markersize=12, markeredgecolor='black', zorder=21)

    if cv_max_point is not None:
        ax1.plot(cv_max_point['ã‚³ã‚¹ãƒˆ'], cv_max_point['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'], 's', color='darkviolet', markersize=12, markeredgecolor='white', label='CVæœ€å¤§åŒ–ç‚¹', zorder=21)
        ax2.plot(cv_max_point['ã‚³ã‚¹ãƒˆ'], cv_max_point['äºˆæ¸¬CPA'], 's', color='darkviolet', markersize=12, markeredgecolor='white', zorder=21)

    # å‡¡ä¾‹ã‚’ã¾ã¨ã‚ã‚‹
    lines, labels = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    # é‡è¤‡ãƒ©ãƒ™ãƒ«ã‚’å‰Šé™¤
    from collections import OrderedDict
    all_labels = labels + labels2
    all_lines = lines + lines2
    by_label = OrderedDict(zip(all_labels, all_lines))
    ax2.legend(by_label.values(), by_label.keys(), loc='best', fontsize=12, frameon=True, shadow=True)
    
    fig.tight_layout()
    return fig


# ============== UI: ã‚µã‚¤ãƒ‰ãƒãƒ¼ ==============
with st.sidebar:
    st.markdown("## âš™ï¸ è¨­å®šãƒ‘ãƒãƒ«")
    
    with st.expander("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=True):
        uploaded_file = st.file_uploader(
            "ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ¬ãƒãƒ¼ãƒˆ (CSV)", 
            type="csv",
            help="æ—¥ä»˜ã‚«ãƒ©ãƒ ï¼ˆ'æ—¥'ã¾ãŸã¯'æ—¥ä»˜'ï¼‰ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )

    st.markdown("---")
    st.markdown("## ğŸ› ï¸ ãƒ¢ãƒ‡ãƒ«è©³ç´°è¨­å®š")
    recency_days = st.number_input("ç›´è¿‘ã¨è¦‹ãªã™æœŸé–“ï¼ˆæ—¥ï¼‰", min_value=1, max_value=90, value=30, step=1)
    recency_weight = st.slider("ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ã®é‡ã¿", min_value=1.0, max_value=5.0, value=2.0, step=0.1)

    st.markdown("---")
    st.markdown("## äºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    input_budget = st.number_input(
        "äºˆæ¸¬ã—ãŸã„äºˆç®—ï¼ˆå††ï¼‰ã‚’å…¥åŠ›", 
        min_value=0, 
        value=None, 
        placeholder="ä¾‹: 50000", 
        step=1000, 
        help="ä»»æ„ã®äºˆç®—é¡ã‚’å††å˜ä½ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    )


# ============== UI: ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ ==============
st.title('ğŸ’¡ CPAäºˆæ¸¬ãƒ¢ãƒ‡ãƒ« v3.0')
st.markdown("éå»ã®åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æœ€é©ãªåºƒå‘Šäºˆç®—ã¨ç›®æ¨™CPAã‚’ãƒ‡ãƒ¼ã‚¿ãƒ‰ãƒªãƒ–ãƒ³ã§å°ãå‡ºã—ã¾ã™ã€‚")

with st.expander("ğŸš€ ã“ã®ãƒ„ãƒ¼ãƒ«ã®ç‰¹å¾´"):
    st.markdown("""
    - **å˜ä¸€ãƒ•ã‚¡ã‚¤ãƒ«ã§åˆ†æ**: æ—¥ä»˜ã‚«ãƒ©ãƒ ã‚’å«ã‚€CSVã‚’1ã¤ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ã ã‘ã§ã€ã™ãã«åˆ†æã‚’é–‹å§‹ã§ãã¾ã™ã€‚
    - **æˆ¦ç•¥ãƒ—ãƒ©ãƒ³ã®è‡ªå‹•ææ¡ˆ**: ã€ŒåŠ¹ç‡é‡è¦–ã€ã¨ã€Œç²å¾—é‡è¦–ã€ã®2ã¤ã®æˆ¦ç•¥ãƒ—ãƒ©ãƒ³ã‚’è‡ªå‹•ã§ç®—å‡ºã—ã€æ„æ€æ±ºå®šã‚’ã‚µãƒãƒ¼ãƒˆã—ã¾ã™ã€‚
    - **é«˜ç²¾åº¦ãªäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«**: LightGBMã‚’æ¡ç”¨ã—ã€ç‰¹å¾´é‡ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°ã‚’å°å…¥ã™ã‚‹ã“ã¨ã§ã€ã‚ˆã‚Šç¾å®Ÿã«å³ã—ãŸäºˆæ¸¬ã‚’æä¾›ã—ã¾ã™ã€‚
    - **ä¿¡é ¼æ€§ã®å¯è¦–åŒ–**: ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬èª¤å·®ï¼ˆMAEï¼‰ã‚’æç¤ºã—ã€äºˆæ¸¬çµæœã®ä¿¡é ¼æ€§ã‚’å®¢è¦³çš„ã«åˆ¤æ–­ã§ãã¾ã™ã€‚
    """)

st.markdown("---")

# ============== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==============
if uploaded_file:
    with st.spinner('ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ä¸­ã§ã™...'):
        df_cleaned, log_messages, error_message = load_and_preprocess_data(uploaded_file, recency_days, recency_weight)

    if error_message:
        st.error(error_message)
    else:
        with st.spinner('äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ãƒ»è©•ä¾¡ä¸­ã§ã™...'):
            main_model, feature_importance, avg_mae = train_and_evaluate_model(df_cleaned)
            sim_models = create_simulation_models(df_cleaned)

        st.success("ãƒ¢ãƒ‡ãƒ«ã®æº–å‚™ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")

        with st.container(border=True):
            st.markdown("#### ğŸ§  ãƒ¢ãƒ‡ãƒ«ã®ä¿¡é ¼æ€§")
            st.metric(label="äºˆæ¸¬èª¤å·®ã®å¹³å‡ï¼ˆMAEï¼‰", value=f"{avg_mae:.2f} ä»¶",
                      help="ã“ã®ãƒ¢ãƒ‡ãƒ«ã®äºˆæ¸¬ã«ã¯ã€å¹³å‡ã—ã¦ã“ã‚Œãã‚‰ã„ã®ä»¶æ•°ã®èª¤å·®ãŒè¦‹è¾¼ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¤ºã—ã¾ã™ã€‚å€¤ãŒå°ã•ã„ã»ã©ä¿¡é ¼æ€§ãŒé«˜ã„ã¨åˆ¤æ–­ã§ãã¾ã™ã€‚")

        # ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã¨æˆ¦ç•¥ãƒ—ãƒ©ãƒ³ã®è¨ˆç®—
        # input_budgetãŒNoneã§ã‚‚ã‚°ãƒ©ãƒ•æç”»ã®ãŸã‚ã«ä¸€åº¦å®Ÿè¡Œ
        sim_budget = input_budget if input_budget is not None else df_cleaned['ã‚³ã‚¹ãƒˆ'].median()
        sim_df = run_simulation(df_cleaned, main_model, sim_models, sim_budget)

        if not sim_df.empty:
            cpa_best_point = sim_df.loc[sim_df['äºˆæ¸¬CPA'].idxmin()]
            cv_max_point = sim_df.loc[sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'].idxmax()]

            st.markdown("---")
            st.markdown("### ğŸ“ˆ æˆ¦ç•¥ãƒ—ãƒ©ãƒ³ã®ã”ææ¡ˆ")
            st.markdown("ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ãã€2ã¤ã®æˆ¦ç•¥çš„ãªé¸æŠè‚¢ã‚’ç®—å‡ºã—ã¾ã—ãŸã€‚")

            col1, col2 = st.columns(2)
            with col1:
                with st.container(border=True):
                    st.markdown("##### ğŸ¥‡ åŠ¹ç‡é‡è¦–ãƒ—ãƒ©ãƒ³ (CPAæœ€è‰¯åŒ–)")
                    st.metric("æ¨å¥¨äºˆç®—", f"{cpa_best_point['ã‚³ã‚¹ãƒˆ']:,.0f} å††")
                    st.metric("äºˆæ¸¬CPA", f"{cpa_best_point['äºˆæ¸¬CPA']:,.0f} å††")
                    st.metric("äºˆæ¸¬CVæ•°", f"{cpa_best_point['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°']:.2f} ä»¶")
            with col2:
                with st.container(border=True):
                    st.markdown("##### ğŸš€ ç²å¾—é‡è¦–ãƒ—ãƒ©ãƒ³ (CVæœ€å¤§åŒ–)")
                    st.metric("æ¨å¥¨äºˆç®—", f"{cv_max_point['ã‚³ã‚¹ãƒˆ']:,.0f} å††")
                    st.metric("äºˆæ¸¬CPA", f"{cv_max_point['äºˆæ¸¬CPA']:,.0f} å††")
                    st.metric("äºˆæ¸¬CVæ•°", f"{cv_max_point['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°']:.2f} ä»¶")
        else:
            cpa_best_point, cv_max_point = None, None
            st.warning("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãŒç©ºã®ãŸã‚ã€æˆ¦ç•¥ãƒ—ãƒ©ãƒ³ã‚’ææ¡ˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")

        # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›äºˆç®—ã§ã®äºˆæ¸¬
        predicted_cv_user, predicted_cpa_user = None, None
        if input_budget is not None and input_budget > 0:
            sim_df_user = run_simulation(df_cleaned, main_model, sim_models, input_budget)
            if not sim_df_user.empty:
                # å…¥åŠ›äºˆç®—ã«æœ€ã‚‚è¿‘ã„è¡Œã‚’å–å¾—
                user_point = sim_df_user.iloc[(sim_df_user['ã‚³ã‚¹ãƒˆ']-input_budget).abs().argsort()[:1]]
                predicted_cv_user = user_point['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'].iloc[0]
                predicted_cpa_user = user_point['äºˆæ¸¬CPA'].iloc[0]

                st.markdown("---")
                st.markdown(f"### äºˆç®— **{input_budget:,.0f}å††** ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
                
                max_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].max()
                if input_budget > max_cost_data * 1.1:
                    st.warning(f"âš ï¸ **è­¦å‘Š:** å…¥åŠ›ã•ã‚ŒãŸäºˆç®—ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§ã‚³ã‚¹ãƒˆ ({max_cost_data:,.0f}å††) ã‚’å¤§ããè¶…ãˆã¦ã„ã¾ã™ã€‚äºˆæ¸¬ã¯å¤–æŒ¿ã§ã‚ã‚Šã€ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

                col1_user, col2_user = st.columns(2)
                with col1_user:
                    st.metric(label="ğŸ¯ äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°", value=f"{predicted_cv_user:.2f} ä»¶")
                with col2_user:
                    cpa_display = f"{predicted_cpa_user:,.0f} å††" if pd.notna(predicted_cpa_user) else "ç®—å‡ºä¸å¯"
                    st.metric(label="ğŸ’° äºˆæ¸¬CPA", value=cpa_display)

        # ã‚°ãƒ©ãƒ•ã¨è©³ç´°æƒ…å ±ã®è¡¨ç¤º
        tab1, tab2, tab3 = st.tabs(["ğŸ“Š **äºˆæ¸¬çµæœã®å…¨ä½“åƒã‚°ãƒ©ãƒ•**", "ğŸ§  **ãƒ¢ãƒ‡ãƒ«ã®åˆ†ææƒ…å ±**", "ğŸ“„ **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©³ç´°**"])

        with tab1:
            if not sim_df.empty:
                with st.spinner('ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆä¸­ã§ã™...'):
                    fig = create_plot(sim_df, input_budget, predicted_cv_user, predicted_cpa_user, cpa_best_point, cv_max_point)
                    st.pyplot(fig)
            else:
                st.warning("ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãŒç©ºã®ãŸã‚ã€ã‚°ãƒ©ãƒ•ã‚’æç”»ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
        with tab2:
            st.markdown("#### ãƒ¢ãƒ‡ãƒ«ã®ç‰¹å¾´é‡é‡è¦åº¦")
            st.markdown("ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ãŒã€ã©ã®æŒ‡æ¨™ã‚’é‡è¦–ã—ã¦äºˆæ¸¬ã‚’è¡Œã£ãŸã‹ã‚’ç¤ºã—ã¾ã™ã€‚")
            st.dataframe(feature_importance.style.background_gradient(cmap='viridis', subset=['é‡è¦åº¦']))
            st.markdown("---")
            st.markdown("#### ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚°")
            st.code("\n".join(log_messages))
        with tab3:
            st.markdown("ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆç‰¹å¾´é‡ç”Ÿæˆãƒ»å¤–ã‚Œå€¤é™¤å»å¾Œï¼‰ã§ã™ã€‚")
            st.dataframe(df_cleaned.head(100))
            
else:
    st.info('ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‹ã‚‰ã€åˆ†æç”¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚')

