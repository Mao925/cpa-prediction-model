# -*- coding: utf-8 -*-
import streamlit as st
import pandas as pd
import numpy as np
import lightgbm as lgb
from sklearn.linear_model import LinearRegression
import matplotlib.pyplot as plt
import japanize_matplotlib
import warnings
import io

# è­¦å‘Šã‚’éè¡¨ç¤ºã«ã™ã‚‹
warnings.filterwarnings('ignore')

# Matplotlibã®ã‚¹ã‚¿ã‚¤ãƒ«ã‚’è¨­å®š
plt.style.use('seaborn-v0_8-whitegrid')

# ============== Streamlit ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®UIè¨­å®š ==============
st.set_page_config(
    page_title="CPAäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«",
    page_icon="ï¿½",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ã‚«ã‚¹ã‚¿ãƒ CSSã§è¦‹ãŸç›®ã‚’èª¿æ•´ ---
st.markdown("""
<style>
    .stMetric {
        border-radius: 10px;
        padding: 15px;
        background-color: #f0f2f6;
    }
    .st-emotion-cache-1r4qj8v {
        border-radius: 10px;
    }
</style>
""", unsafe_allow_html=True)


# ============== é–¢æ•°ã®å®šç¾© (å¤‰æ›´ãªã—) ==============

@st.cache_data
def load_and_preprocess_data(file_all, file_30d):
    if file_all is None or file_30d is None:
        return None, None, "ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚µã‚¤ãƒ‰ãƒãƒ¼ã‹ã‚‰2ã¤ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
    log_messages = []
    def read_csv_robust(file):
        encodings = ['shift_jis', 'cp932', 'utf-8']
        file.seek(0)
        for encoding in encodings:
            try:
                return pd.read_csv(file, encoding=encoding)
            except UnicodeDecodeError:
                file.seek(0)
                continue
        raise UnicodeDecodeError(f"ãƒ•ã‚¡ã‚¤ãƒ« '{file.name}' ã‚’ã©ã®ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°ã§ã‚‚èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    try:
        df_all = read_csv_robust(file_all)
        df_30d = read_csv_robust(file_30d)
        log_messages.append("âœ… CSVãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«æˆåŠŸã—ã¾ã—ãŸã€‚")
    except Exception as e:
        return None, None, f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}"
    df_all['weight'] = 1.0
    df_30d['weight'] = 2.0
    log_messages.append(f"âœ… ãƒ¢ãƒ‡ãƒ«ãŒç›´è¿‘ã®ãƒ‡ãƒ¼ã‚¿({file_30d.name})ã‚’é‡è¦–ã™ã‚‹ã‚ˆã†ã«ã€é‡ã¿ã‚’2.0ã«èª¿æ•´ã—ã¾ã—ãŸã€‚")
    df = pd.concat([df_all, df_30d], ignore_index=True)
    df.columns = df.columns.str.replace(' ', '').str.replace('ã€€', '')
    required_columns = ['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'ã‚¯ãƒªãƒƒã‚¯ç‡', 'ã‚³ã‚¹ãƒˆ', 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢', 'ãƒšãƒ¼ã‚¸æœ€ä¸Šéƒ¨ã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢']
    required_columns_with_weight = required_columns + ['weight']
    missing_cols = [col for col in required_columns if col not in df.columns]
    if missing_cols:
        return None, None, f"âŒ å¿…è¦ãªã‚«ãƒ©ãƒ ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {missing_cols}ã€‚åˆ©ç”¨å¯èƒ½ãªã‚«ãƒ©ãƒ : {df.columns.tolist()}"
    for col in required_columns:
        if df[col].dtype == 'object':
            df[col] = df[col].astype(str).str.replace('%', '', regex=False).str.replace(',', '', regex=False)
        df[col] = pd.to_numeric(df[col], errors='coerce')
    df.dropna(subset=required_columns_with_weight, inplace=True)
    log_messages.append("âœ… ãƒ‡ãƒ¼ã‚¿å‹ã®ã‚¯ãƒ¬ãƒ³ã‚¸ãƒ³ã‚°ã¨æ¬ æå€¤ã®é™¤å»ã‚’è¡Œã„ã¾ã—ãŸã€‚")
    Q1, Q3 = df['ã‚³ã‚¹ãƒˆ'].quantile(0.25), df['ã‚³ã‚¹ãƒˆ'].quantile(0.75)
    IQR = Q3 - Q1
    lower_bound, upper_bound = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
    original_rows = len(df)
    df_cleaned = df[(df['ã‚³ã‚¹ãƒˆ'] >= lower_bound) & (df['ã‚³ã‚¹ãƒˆ'] <= upper_bound)].copy()
    log_messages.append(f"âœ… å¤–ã‚Œå€¤ã‚’é™¤å»ã—ã¾ã—ãŸã€‚(å…ƒã®ãƒ‡ãƒ¼ã‚¿æ•°: {original_rows}, é™¤å»å¾Œ: {len(df_cleaned)})")
    if len(df_cleaned) < 10:
         return None, None, "âŒ å‰å‡¦ç†å¾Œã®ãƒ‡ãƒ¼ã‚¿ãŒå°‘ãªã™ãã¾ã™ã€‚ååˆ†ãªãƒ‡ãƒ¼ã‚¿é‡ã®ã‚ã‚‹CSVã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
    log_messages.append("âœ… ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
    return df_cleaned, log_messages, None

@st.cache_resource
def train_models(_df_cleaned):
    features_for_sub_models = ['ã‚³ã‚¹ãƒˆ']
    sub_models = {}
    dependent_features = ['ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³æ•°', 'ã‚¯ãƒªãƒƒã‚¯æ•°', 'ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢', 'ãƒšãƒ¼ã‚¸æœ€ä¸Šéƒ¨ã®ã‚¤ãƒ³ãƒ—ãƒ¬ãƒƒã‚·ãƒ§ãƒ³ã‚·ã‚§ã‚¢']
    for feature in dependent_features:
        X_sub, y_sub, weights_sub = _df_cleaned[features_for_sub_models], _df_cleaned[feature], _df_cleaned['weight']
        sub_model = lgb.LGBMRegressor(random_state=42, objective='regression_l1')
        sub_model.fit(X_sub, y_sub, sample_weight=weights_sub)
        sub_models[feature] = sub_model
    main_features = ['ã‚³ã‚¹ãƒˆ'] + dependent_features
    target = 'ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'
    X_main, y_main, weights_main = _df_cleaned[main_features], _df_cleaned[target], _df_cleaned['weight']
    main_model = LinearRegression()
    main_model.fit(X_main, y_main, sample_weight=weights_main)
    coefficients = pd.DataFrame(main_model.coef_, X_main.columns, columns=['å›å¸°ä¿‚æ•°'])
    return sub_models, main_model, coefficients

def run_simulation(df_cleaned, sub_models, main_model, input_budget):
    min_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].min()
    max_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].max()
    graph_max_cost = max(max_cost_data, input_budget) * 1.1
    num_steps = max(200, int((graph_max_cost - min_cost_data) / 1000))
    cost_range = np.linspace(min_cost_data, graph_max_cost, num_steps)
    sim_results = []
    main_features = ['ã‚³ã‚¹ãƒˆ'] + list(sub_models.keys())
    for cost in cost_range:
        sim_data = {'ã‚³ã‚¹ãƒˆ': cost}
        for feature, model in sub_models.items():
            sim_data[feature] = model.predict(pd.DataFrame({'ã‚³ã‚¹ãƒˆ': [cost]}))[0]
        sim_df_row = pd.DataFrame([sim_data])
        predicted_cv = main_model.predict(sim_df_row[main_features])[0]
        sim_results.append({'ã‚³ã‚¹ãƒˆ': cost, 'äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°': predicted_cv})
    sim_df = pd.DataFrame(sim_results)
    sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] = sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'].clip(lower=0)
    sim_df['äºˆæ¸¬CPA'] = sim_df.apply(lambda r: r['ã‚³ã‚¹ãƒˆ'] / r['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] if r['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'] > 0.01 else np.nan, axis=1)
    sim_df.dropna(subset=['äºˆæ¸¬CPA'], inplace=True)
    return sim_df

def create_plot(sim_df, input_budget, predicted_cv, predicted_cpa):
    fig, ax1 = plt.subplots(figsize=(12, 7))
    color = 'royalblue'
    ax1.set_xlabel('äºˆç®—ï¼ˆã‚³ã‚¹ãƒˆï¼‰[å††]', fontsize=14)
    ax1.set_ylabel('äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', fontsize=14, color=color)
    ax1.plot(sim_df['ã‚³ã‚¹ãƒˆ'], sim_df['äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°'], linestyle='-', color=color, label='äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°', linewidth=2.5)
    ax1.tick_params(axis='y', labelcolor=color)
    ax1.grid(True, which='both', linestyle='--', linewidth=0.5)
    ax2 = ax1.twinx()
    color = 'mediumseagreen'
    ax2.set_ylabel('äºˆæ¸¬CPA [å††]', fontsize=14, color=color)
    ax2.plot(sim_df['ã‚³ã‚¹ãƒˆ'], sim_df['äºˆæ¸¬CPA'], linestyle='--', color=color, label='äºˆæ¸¬CPA', linewidth=2.5)
    ax2.tick_params(axis='y', labelcolor=color)
    if predicted_cv is not None and predicted_cpa is not None:
        ax1.axvline(x=input_budget, color='tomato', linestyle=':', linewidth=2, label=f"å…¥åŠ›äºˆç®—: {input_budget:,.0f}å††")
        ax1.plot(input_budget, predicted_cv, 'o', color='tomato', markersize=10, markeredgecolor='white', markeredgewidth=1.5)
        ax2.plot(input_budget, predicted_cpa, 'o', color='tomato', markersize=10, markeredgecolor='white', markeredgewidth=1.5)
    lines, labels = ax1.get_legend_handles_labels()
    lines2, labels2 = ax2.get_legend_handles_labels()
    ax2.legend(lines + lines2, labels + labels2, loc='upper left', fontsize=12, frameon=True, shadow=True)
    fig.tight_layout()
    return fig


# ============== UI: ã‚µã‚¤ãƒ‰ãƒãƒ¼ ==============
with st.sidebar:
    st.markdown("## âš™ï¸ è¨­å®šãƒ‘ãƒãƒ«")
    
    with st.expander("ğŸ“ ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", expanded=True):
        uploaded_file_all = st.file_uploader(
            "1. å…¨æœŸé–“ãƒ‡ãƒ¼ã‚¿ (CSV)", 
            type="csv",
            help="éå»ã®å…¨ã¦ã®åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )
        uploaded_file_30d = st.file_uploader(
            "2. ç›´è¿‘ãƒ‡ãƒ¼ã‚¿ (CSV)", 
            type="csv",
            help="äºˆæ¸¬ã§ç‰¹ã«é‡è¦–ã—ãŸã„ç›´è¿‘æœŸé–“ï¼ˆä¾‹: éå»30æ—¥é–“ï¼‰ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚"
        )

    st.markdown("---")
    st.markdown("## äºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³")
    input_budget = st.number_input(
        "äºˆæ¸¬ã—ãŸã„äºˆç®—ï¼ˆå††ï¼‰ã‚’å…¥åŠ›", 
        min_value=0, 
        value=None, 
        placeholder="ä¾‹: 50000", 
        step=1000, 
        help="ä»»æ„ã®äºˆç®—é¡ã‚’å††å˜ä½ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    )
    
    recommendation_placeholder = st.empty()


# ============== UI: ãƒ¡ã‚¤ãƒ³ãƒšãƒ¼ã‚¸ ==============
st.title('ğŸ“ˆ CPAäºˆæ¸¬ãƒ¢ãƒ‡ãƒ«')
st.markdown("éå»ã®åºƒå‘Šãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ã€æœ€é©ãªåºƒå‘Šäºˆç®—ã‚’è¦‹ã¤ã‘å‡ºã—ã¾ã—ã‚‡ã†ã€‚")

with st.expander("ğŸ’¡ ä½¿ã„æ–¹ã‚¬ã‚¤ãƒ‰"):
    st.markdown("""
    1.  **ãƒ‡ãƒ¼ã‚¿ã®æº–å‚™**: `ã‚³ã‚¹ãƒˆ`, `ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°`ãªã©ã€æŒ‡å®šã•ã‚ŒãŸã‚«ãƒ©ãƒ ã‚’å«ã‚€CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’2ç¨®é¡ï¼ˆå…¨æœŸé–“ãƒ»ç›´è¿‘ï¼‰ç”¨æ„ã—ã¾ã™ã€‚
    2.  **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‹ã‚‰ã€ç”¨æ„ã—ãŸ2ã¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚
    3.  **äºˆç®—ã®å…¥åŠ›**: ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œäºˆç®—ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã€ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§ã€äºˆæ¸¬ã—ãŸã„äºˆç®—é¡ã‚’å…¥åŠ›ã—ã¾ã™ã€‚
    4.  **çµæœã®ç¢ºèª**: å…¥åŠ›å¾Œã€å³åº§ã«äºˆæ¸¬çµæœãŒãƒ¡ã‚¤ãƒ³ç”»é¢ã«è¡¨ç¤ºã•ã‚Œã¾ã™ã€‚ã‚°ãƒ©ãƒ•ã‚„è©³ç´°æƒ…å ±ã‚’ç¢ºèªã—ã€äºˆç®—è¨ˆç”»ã®å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚
    """)

st.markdown("---")

# ============== ãƒ¡ã‚¤ãƒ³å‡¦ç† ==============
if uploaded_file_all and uploaded_file_30d:
    with st.spinner('ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã€ãƒ¢ãƒ‡ãƒ«ã‚’æº–å‚™ä¸­ã§ã™...'):
        df_cleaned, log_messages, error_message = load_and_preprocess_data(uploaded_file_all, uploaded_file_30d)

    if error_message:
        st.error(error_message)
    else:
        min_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].min()
        max_cost_data = df_cleaned['ã‚³ã‚¹ãƒˆ'].max()
        with recommendation_placeholder.container():
            st.markdown("##### **æ¨å¥¨äºˆç®—ç¯„å›²**")
            st.info(f"{min_cost_data:,.0f} å†† ã€œ {max_cost_data:,.0f} å††")
            st.caption("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ãŸã€äºˆæ¸¬ç²¾åº¦ãŒæ¯”è¼ƒçš„å®‰å®šã—ã¦ã„ã‚‹ç¯„å›²ã§ã™ã€‚")

        with st.spinner('äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«ã‚’å­¦ç¿’ä¸­ã§ã™...'):
            sub_models, main_model, coefficients = train_models(df_cleaned)

        if input_budget is not None and input_budget > 0:
            sim_data_user = {'ã‚³ã‚¹ãƒˆ': float(input_budget)}
            for feature, model in sub_models.items():
                sim_data_user[feature] = model.predict(pd.DataFrame({'ã‚³ã‚¹ãƒˆ': [input_budget]}))[0]
            
            sim_df_user_row = pd.DataFrame([sim_data_user])
            main_features = ['ã‚³ã‚¹ãƒˆ'] + list(sub_models.keys())
            predicted_cv_user = main_model.predict(sim_df_user_row[main_features])[0]
            predicted_cv_user = max(0, predicted_cv_user)
            predicted_cpa_user = input_budget / predicted_cv_user if predicted_cv_user > 0.01 else float('inf')
            
            st.markdown(f"### äºˆç®— **{input_budget:,.0f}å††** ã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœ")
            
            if input_budget > max_cost_data:
                st.warning(f"âš ï¸ **è­¦å‘Š:** å…¥åŠ›ã•ã‚ŒãŸäºˆç®—ã¯ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ€å¤§ã‚³ã‚¹ãƒˆ ({max_cost_data:,.0f}å††) ã‚’è¶…ãˆã¦ã„ã¾ã™ã€‚äºˆæ¸¬ç²¾åº¦ãŒä½ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

            col1, col2 = st.columns(2)
            with col1:
                st.metric(label="ğŸ¯ äºˆæ¸¬ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°", value=f"{predicted_cv_user:.2f} ä»¶")
            with col2:
                cpa_display = f"{predicted_cpa_user:,.0f} å††" if predicted_cpa_user != float('inf') else "ç®—å‡ºä¸å¯"
                st.metric(label="ğŸ’° äºˆæ¸¬CPA", value=cpa_display)

            with st.spinner('ã‚°ãƒ©ãƒ•ã‚’ç”Ÿæˆä¸­ã§ã™...'):
                sim_df = run_simulation(df_cleaned, sub_models, main_model, input_budget)
                fig = create_plot(sim_df, input_budget, predicted_cv_user, predicted_cpa_user)
            
            tab1, tab2, tab3 = st.tabs(["ğŸ“Š **äºˆæ¸¬çµæœã®å…¨ä½“åƒã‚°ãƒ©ãƒ•**", "ğŸ“„ **å­¦ç¿’ãƒ‡ãƒ¼ã‚¿è©³ç´°**", "ğŸ§  **ãƒ¢ãƒ‡ãƒ«ã®åˆ†ææƒ…å ±**"])

            with tab1:
                st.pyplot(fig)
            with tab2:
                st.markdown("ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ã«ä½¿ç”¨ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ï¼ˆå¤–ã‚Œå€¤é™¤å»å¾Œï¼‰ã®ã‚µãƒ³ãƒ—ãƒ«ã§ã™ã€‚")
                st.dataframe(df_cleaned.head(100))
            with tab3:
                st.markdown("#### é‡å›å¸°ãƒ¢ãƒ‡ãƒ«ã®å›å¸°ä¿‚æ•°")
                st.markdown("å„æŒ‡æ¨™ãŒ1å˜ä½å¢—åŠ ã—ãŸã¨ãã«ã€ã‚³ãƒ³ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°ãŒã©ã‚Œã ã‘å¢—æ¸›ã™ã‚‹ã‹ã‚’ç¤ºã—ã¾ã™ã€‚")
                st.table(coefficients.style.format("{:.4f}").background_gradient(cmap='viridis'))
                st.markdown("---")
                st.markdown("#### ãƒ‡ãƒ¼ã‚¿å‡¦ç†ãƒ­ã‚°")
                st.code("\n".join(log_messages))
        else:
            st.info("ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§äºˆç®—ã‚’å…¥åŠ›ã™ã‚‹ã¨ã€ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³çµæœãŒè¡¨ç¤ºã•ã‚Œã¾ã™ã€‚")

else:
    st.info('ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€Œãƒ‡ãƒ¼ã‚¿ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã€ã‹ã‚‰ã€åˆ†æç”¨ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’2ã¤ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚')
